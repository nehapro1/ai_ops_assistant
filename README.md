ğŸ¤– AI Ops Assistant

A multi-agent system designed to handle operational tasks such as weather checks and GitHub repository searches.
Built using FastAPI, Groq (Llama 3.3), and integrated third-party APIs.

ğŸ—ï¸ Architecture Overview

The system follows a Multi-Agent Orchestration pattern to ensure:

Modularity

Scalability

Reliability

ğŸ§  Planner Agent

Receives the user query

Uses an LLM to break the query into tool-specific steps

Outputs a structured JSON plan

âš™ï¸ Executor Agent

Acts as a deterministic controller

Maps tool names to Python functions

Executes real-world API calls

âœ… Verifier Agent

Validates raw outputs

Ensures the final response:

Matches the original user query

Is complete and accurate

ğŸ› ï¸ Integrated APIs
ğŸŒ¦ï¸ Open-Meteo API

Provides real-time weather data

ğŸ§‘â€ğŸ’» GitHub Search API

Fetches top repositories based on:

â­ Star count

ğŸ” Keyword relevance

ğŸš€ Local Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone <your-repo-url>
cd ai_ops_assistant

2ï¸âƒ£ Create a Virtual Environment
python -m venv venv


Activate it:

Mac / Linux

source venv/bin/activate


Windows

venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Environment Variables

Create a .env file in the root directory (refer to .env.example):

GROQ_API_KEY=your_actual_groq_api_key

5ï¸âƒ£ Run the Server
uvicorn main:app --reload

ğŸ§ª Example Prompts
ğŸŒ¦ï¸ Weather

"What is the weather in London?"

"How is the weather in New York?"

ğŸ§‘â€ğŸ’» GitHub Search

"Find top Python repositories for Machine Learning on GitHub"

"Find me a GitHub repo for FastAPI"

ğŸ”€ Combined Query

"How is the weather in New York and find me a GitHub repo for FastAPI?"

ğŸ” Usage & Debugging

By default, the API returns a clean, human-readable response suitable for production.

âœ… Clean Answer
http://127.0.0.1:8000/run?query=How is the weather in London?

ğŸ› ï¸ Debug Mode (Agent Logs)

To inspect:

Planner steps

Executor API responses

Append debug=true:

http://127.0.0.1:8000/run?query=How is the weather in London?&debug=true

âš ï¸ Known Limitations & Tradeoffs
â±ï¸ GitHub API Rate Limits

Uses unauthenticated access

Limited to 60 requests/hour per IP

ğŸ” Sequential Execution

Agent steps run one-by-one

Parallel execution could reduce latency for complex queries

ğŸ§  Context Window Constraints

Extremely long queries with many subtasks may hit LLM token limits during planning
